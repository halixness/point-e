{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709332b8",
   "metadata": {},
   "source": [
    "### Test 6\n",
    "## Evaluating the quality of POINT-E generated clouds with CAD objects\n",
    "In this notebook we evaluate the quality of pre-trained POINT-E (300M, 1B) on two datasets:\n",
    "- ModelNet40\n",
    "- ShapeNetv0\n",
    "\n",
    "Two variants of our solution are evaluated:\n",
    "- **Patch concatenation multi-view:** the model is conditioned on all the available views at each inference step\n",
    "- **Stochastic conditioning:** the model is conditioned on a single random view from the set of available ones at each inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae038a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import wasserstein_distance\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from mv_point_e.evals.feature_extractor import PointNetClassifier, get_torch_devices\n",
    "from mv_point_e.evals.fid_is import compute_statistics\n",
    "from mv_point_e.evals.fid_is import compute_inception_score\n",
    "\n",
    "from mv_point_e.models.download import load_checkpoint\n",
    "from mv_point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from mv_point_e.diffusion.sampler import PointCloudSampler\n",
    "from mv_point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def views_to_pointcloud(views, n_views=None):\n",
    "    \"\"\" \n",
    "        Generate a K-point cloud from a list of n-views\n",
    "        in:     Tensor(n, w, h, 3), int(n)\n",
    "        out:    Tensor(1, K, (x, y, z, r, g, b))\n",
    "    \"\"\"\n",
    "\n",
    "    base_name = 'base300M' # base40M, use base300M or base1B for better results\n",
    "\n",
    "    if n_views is not None:\n",
    "        MODEL_CONFIGS[base_name][\"n_views\"] = n_views\n",
    "        MODEL_CONFIGS['upsample'][\"n_views\"] = n_views\n",
    "\n",
    "    # Instantiate POINT-E and load pre-trained weights\n",
    "    print('[-] creating base model...')\n",
    "    base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
    "    base_model.eval()\n",
    "    base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
    "\n",
    "    print('[-] creating upsample model...')\n",
    "    upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "    upsampler_model.eval()\n",
    "    upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "\n",
    "    print(\"[-] Loading pretrained models...\")\n",
    "    base_model.load_state_dict(load_checkpoint(base_name, device))\n",
    "    upsampler_model.load_state_dict(load_checkpoint('upsample', device))\n",
    "\n",
    "    sampler = PointCloudSampler(\n",
    "        device=device,\n",
    "        models=[base_model, upsampler_model],\n",
    "        diffusions=[base_diffusion, upsampler_diffusion],\n",
    "        num_points=[num_points, 4096-num_points], # points in cloud and missing ones for upsampling\n",
    "        aux_channels=['R', 'G', 'B'],\n",
    "        guidance_scale=[3.0, 3.0],\n",
    "    )\n",
    "\n",
    "    # Produce a sample from the model, iterative diffusion process\n",
    "    samples = None\n",
    "    for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(images=views))):\n",
    "        samples = x\n",
    "\n",
    "    if n_views is not None:\n",
    "        del MODEL_CONFIGS[base_name][\"n_views\"]\n",
    "        del MODEL_CONFIGS['upsample'][\"n_views\"]\n",
    "    del sampler\n",
    "    del base_model\n",
    "    del base_diffusion\n",
    "    del upsampler_model\n",
    "    del upsampler_diffusion\n",
    "\n",
    "    return samples\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "def cloud_distance(cloud1, cloud2, metric=None):\n",
    "    \"\"\" \n",
    "        Compute distance between 1d distributions of cloud p2 norms \n",
    "        in:     Tensor((x, y, z), K), Tensor((x, y, z), K) \n",
    "        out:    Float\n",
    "    \"\"\"\n",
    "    D1 = torch.cdist(cloud1, cloud1, p=2)\n",
    "    D2 = torch.cdist(cloud2, cloud2, p=2)\n",
    "    X1 = [float(1/i.sum()) for i in D1]\n",
    "    X2 = [float(1/i.sum()) for i in D2]\n",
    "    \n",
    "    if metric == \"gaussian\":\n",
    "        return np.mean(((np.mean(X1) - np.mean(X2))**2).sum()) / (np.std(X1)**2 + np.std(X2)**2)\n",
    "    else:\n",
    "        return wasserstein_distance(X1, X2) * 1e5\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "def plot_distributions(cloud1, cloud2, labels=[\"cloud1\", \"cloud2\"], idx=0, save_fig=False):\n",
    "    \"\"\" \n",
    "        Plot 1d distributions of cloud p2 norms \n",
    "        in:     Tensor(K, c), Tensor(K, c) \n",
    "    \"\"\"\n",
    "    D1 = torch.cdist(cloud1, cloud1, p=2)\n",
    "    D2 = torch.cdist(cloud2, cloud2, p=2)\n",
    "    \n",
    "    s = pd.DataFrame({\n",
    "        labels[0]: [float(1/i.sum()) for i in D1],\n",
    "        labels[1]: [float(1/i.sum()) for i in D2],\n",
    "      })\n",
    "    s.plot.kde(bw_method=0.4, figsize=(24,8), title=f\"Sample {idx} poincloud pdf of different objects\")\n",
    "    \n",
    "    if save_fig: plt.savefig(f\"{idx}_{labels[0]}_{labels[1]}.png\")\n",
    "    \n",
    "# ----------------------------------------------\n",
    "\n",
    "def sample_PIS(clf, cloud):\n",
    "    \"\"\"\n",
    "        Compute P-IS score for a cloud\n",
    "        in:     PointNetClassifier, Tensor(c, K)\n",
    "        out:    Float\n",
    "        https://github.com/halixness/point-e/blob/69e677d8ea47593c33fe2f52fd40e131054c9ce3/point_e/evals/fid_is.py#L73\n",
    "    \"\"\"\n",
    "    cloud = cloud.unsqueeze(0).cpu().numpy()\n",
    "    \n",
    "    # Feed the point clouds to PointNet => get features and predictions\n",
    "    _, preds = clf.features_and_preds(cloud)\n",
    "\n",
    "    return np.exp(\n",
    "      np.sum(\n",
    "        preds[0] * ( np.log(preds[0]) - np.log(np.mean(preds[0])) )\n",
    "      )\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "def batched_PIS(clf, clouds, ):\n",
    "    \"\"\"\n",
    "        Computes P-IS score for a batch of point clouds\n",
    "        in:   PointNetClassifier, (N, K, c)\n",
    "        out:  Float\n",
    "    \"\"\"\n",
    "    return np.mean([sample_PIS(clf, torch.Tensor(c)) for c in clouds])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def batched_PIS(clf, clouds, batch_size=8):\n",
    "    batches = math.ceil(clouds.shape[0] / batch_size)\n",
    "    dataset_preds = None\n",
    "\n",
    "    for x in range(batches):\n",
    "        xs = clouds[(x * batch_size) : ((x + 1) * batch_size)]\n",
    "        \n",
    "        # Feed the point clouds to PointNet => get features and predictions\n",
    "        _, preds = clf.features_and_preds(xs)\n",
    "\n",
    "        if dataset_preds is None: dataset_preds = preds\n",
    "        else: dataset_preds = np.concatenate((dataset_preds, preds), 0)\n",
    "            \n",
    "    return compute_inception_score(dataset_preds)\n",
    "\"\"\"\n",
    "\n",
    "def batched_PFID(clf, ground_clouds, clouds, batch_size=8):\n",
    "    \"\"\"\n",
    "        Computes P-FID score for pair of batches of point clouds\n",
    "        in:   PointNetClassifier, (N, K, c), (N, K, c)\n",
    "        out:  Float\n",
    "    \"\"\"\n",
    "    batches = math.ceil(ground_clouds.shape[0] / batch_size)\n",
    "    tot_features_1 = None\n",
    "    tot_features_2 = None\n",
    "\n",
    "    for x in range(batches):\n",
    "        \n",
    "        # Grab batched point clouds to compute the scores\n",
    "        gnd = ground_clouds[(x * batch_size) : ((x + 1) * batch_size)]\n",
    "        gen = clouds[(x * batch_size) : ((x + 1) * batch_size)]\n",
    "        \n",
    "        # Feed the point clouds to PointNet => get features and predictions\n",
    "        features_1, _ = clf.features_and_preds(gnd)\n",
    "        if tot_features_1 is None: tot_features_1 = features_1\n",
    "        else: tot_features_1 = np.concatenate((tot_features_1, features_1), 0)\n",
    "        del features_1\n",
    "\n",
    "        features_2, _ = clf.features_and_preds(gen)\n",
    "        if tot_features_2 is None: tot_features_2 = features_2\n",
    "        else: tot_features_2 = np.concatenate((tot_features_2, features_2), 0)\n",
    "        del features_2\n",
    "\n",
    "    # Batched scores are computed\n",
    "    stats_1 = compute_statistics(tot_features_1)\n",
    "    stats_2 = compute_statistics(tot_features_2)    \n",
    "            \n",
    "    return stats_1.frechet_distance(stats_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7dc17f",
   "metadata": {},
   "source": [
    "**Set-up and data loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef31e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ToPILImage = transforms.ToPILImage()\n",
    "num_points = 1024\n",
    "limit = 10\n",
    "default_single_view = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapenet dataset loading\n",
    "base_path = os.path.join(\"..\", \"..\", \"Datasets\", \"shapenet\")\n",
    "views = torch.load(os.path.join(base_path, \"images_obj.pt\"))\n",
    "point_clouds = torch.load(os.path.join(base_path, \"points.pt\"))\n",
    "\n",
    "ground_objs = []\n",
    "\n",
    "for i in range(views.shape[0]):\n",
    "    ground_objs.append([ToPILImage(views[i, j, :, :, :3]) for j in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd72191",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df27111",
   "metadata": {},
   "source": [
    "### Multi-view to point cloud (patch concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate point clouds with point-e in single and multi view mode\n",
    "gen_clouds = torch.zeros((limit, 2, 6, 4096)) # N, 2, c, K\n",
    "exec_time = []\n",
    "\n",
    "for i in range(limit):\n",
    "    \n",
    "    obj = ground_objs[i]\n",
    "    \n",
    "    # Point cloud from single view\n",
    "    print(\"====== Single view ======\")\n",
    "    gen_clouds[i, 0, :, :] = views_to_pointcloud(views = [obj[default_single_view]], n_views = 1)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Point cloud from multi view\n",
    "    print(\"\\n====== Multi view ======\")\n",
    "    t1 = datetime.now()\n",
    "    gen_clouds[i, 1, :, :] = views_to_pointcloud(views = obj, n_views = len(obj))\n",
    "    t2 = datetime.now()\n",
    "    \n",
    "    exec_time.append(t2-t1)\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "exec_time1 = np.mean(exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b466f",
   "metadata": {},
   "source": [
    "### A note on metrics:\n",
    "- **P-FID** is the PointCloud-[Fréchet Inception Distance](https://en.wikipedia.org/wiki/Fréchet_inception_distance), that is the distance between the distance between the distribution of original samples and the distribution of the generated ones, based on the logits from the last lasters of the Inception v3 network.\n",
    "- **P-IS** is the PointCloud-[Inception Score](https://en.wikipedia.org/wiki/Inception_score), which is normally computed to measure the quality of a distribution of synthetic images. The score is maximized when the entropy given the predictions is minimal, that is the prediction is very sharp on a single label. To compute the prediction, an improved version of [PointNet](https://arxiv.org/abs/1612.00593), a 3d point clouds classifier, is used.\n",
    "- **[Wassetstein distance](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html)**: or Earth mover's distance, the distance between two sets of samples. In this case, a set of samples is computed from a single point cloud and it represents the distance from each point to all the others in the cloud (sum for 1d, otherwise a KxK matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PointNet to classify point clouds (and derive semantic score)\n",
    "clf = PointNetClassifier(devices=get_torch_devices(), cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4907a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = torch.zeros((gen_clouds.shape[0], 3))\n",
    "\n",
    "for i in range(gen_clouds.shape[0]):\n",
    "    \n",
    "    print(f\"\\n====== [{i}] Point cloud divergences ======\")\n",
    "    \n",
    "    # ---- ground truth cloud / single view cloud\n",
    "    d_ground_single = cloud_distance(\n",
    "        torch.Tensor(point_clouds[i]), \n",
    "        gen_clouds[i, 0, :3, :].permute(1,0)\n",
    "    )\n",
    "    \n",
    "    print(\"[+] Ground truth - Single view divergence: \\t\\t{}\".format(d_ground_single))\n",
    "\n",
    "    plot_distributions(\n",
    "        torch.Tensor(point_clouds[i]),\n",
    "        gen_clouds[i, 0, :3, :].permute(1,0),\n",
    "        [\"ground_truth\", \"single view\"], \n",
    "        i\n",
    "    )\n",
    "\n",
    "    # ---- ground truth cloud / multi view cloud\n",
    "    d_ground_multi = cloud_distance(\n",
    "        torch.Tensor(point_clouds[i]), \n",
    "        gen_clouds[i, 1, :3, :].permute(1,0)\n",
    "    )\n",
    "    print(\"[+] Ground truth - Multi view divergence: \\t\\t{}\".format(d_ground_multi))\n",
    "\n",
    "    plot_distributions(\n",
    "        torch.Tensor(point_clouds[i]),\n",
    "        gen_clouds[i, 1, :3, :].permute(1,0),\n",
    "        [\"ground_truth\", \"multi view\"], \n",
    "        i\n",
    "    )\n",
    "\n",
    "    # ---- single view cloud / multi view cloud\n",
    "    d_single_multi = cloud_distance(\n",
    "        gen_clouds[i, 0, :3, :].permute(1,0), \n",
    "        gen_clouds[i, 1, :3, :].permute(1,0)\n",
    "    )\n",
    "    print(\"[+] Single view - Multi view divergence: \\t\\t{}\".format(d_single_multi))\n",
    "\n",
    "    plot_distributions(\n",
    "        gen_clouds[i, 0, :3, :].permute(1,0), \n",
    "        gen_clouds[i, 1, :3, :].permute(1,0), \n",
    "        [\"single view\", \"multi view\"], \n",
    "        i\n",
    "    )\n",
    "    \n",
    "    scores[i, :] = torch.Tensor([d_ground_single, d_ground_multi, d_single_multi])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644672a6",
   "metadata": {},
   "source": [
    "**Note:** depending on the choice of the single view and the number of similar objects seen during training, POINT-E can guess the surface of occluded parts correctly or not. Moreover, POINT-E has not been fine-tuned on multiple views yet, it could learn to exploit information from multiple frames for better 3d consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddc2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "endidx = gen_clouds.shape[0] if limit == -1 else limit\n",
    "\n",
    "ground_PIS = batched_PIS(clf, point_clouds[:endidx])\n",
    "single_PIS = batched_PIS(clf, gen_clouds[:, 0, :3, :].permute(0, 2, 1).cpu().numpy())\n",
    "multi_PIS = batched_PIS(clf, gen_clouds[:, 1, :3, :].permute(0, 2, 1).cpu().numpy())\n",
    "\n",
    "print(f\"[+] Ground truth clouds PIS: \\t\\t\\t{ground_PIS}\")\n",
    "print(f\"[+] Single-view generated clouds PIS: \\t\\t{single_PIS}\")\n",
    "print(f\"[+] Multi-view generated clouds PIS: \\t\\t{multi_PIS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6335c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_single_PFID = batched_PFID(clf, \n",
    "    point_clouds[:endidx],\n",
    "    gen_clouds[:, 0, :3, :].permute(0, 2, 1).cpu().numpy()                  \n",
    ")\n",
    "ground_multi_PFID = batched_PFID(clf, \n",
    "    point_clouds[:endidx],\n",
    "    gen_clouds[:, 1, :3, :].permute(0, 2, 1).cpu().numpy()\n",
    ")\n",
    "\n",
    "print(f\"[+] Ground truth - single view P-FID: \\t\\t{ground_single_PFID}\")\n",
    "print(f\"[+] Ground truth - multi view P-FID: \\t\\t{ground_multi_PFID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb134363",
   "metadata": {},
   "source": [
    "### Multi view to point cloud (stochastic conditioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_point_e.models.download import load_checkpoint\n",
    "from sc_point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from sc_point_e.diffusion.sampler import PointCloudSampler\n",
    "from sc_point_e.models.configs import MODEL_CONFIGS, model_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcc382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate point clouds with point-e in single and multi view mode\n",
    "gen_clouds = torch.zeros((limit, 2, 6, 4096)) # N, 2, c, K\n",
    "exec_time = []\n",
    "\n",
    "for i in range(limit):\n",
    "    \n",
    "    obj = ground_objs[i]\n",
    "    \n",
    "    # Point cloud from single view\n",
    "    print(\"====== Single view ======\")\n",
    "    gen_clouds[i, 0, :, :] = views_to_pointcloud(views = [obj[default_single_view]])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Point cloud from multi view\n",
    "    print(\"\\n====== Multi view ======\")\n",
    "    t1 = datetime.now()\n",
    "    gen_clouds[i, 1, :, :] = views_to_pointcloud(views = obj)\n",
    "    t2 = datetime.now()\n",
    "    \n",
    "    exec_time.append(t2-t1)\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "exec_time2 = np.mean(exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4728f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = torch.zeros((gen_clouds.shape[0], 3))\n",
    "\n",
    "for i in range(gen_clouds.shape[0]):\n",
    "    \n",
    "    print(f\"\\n====== [{i}] Point cloud divergences ======\")\n",
    "    \n",
    "    # ---- ground truth cloud / single view cloud\n",
    "    d_ground_single = cloud_distance(\n",
    "        torch.Tensor(point_clouds[i]), \n",
    "        gen_clouds[i, 0, :3, :].permute(1,0)\n",
    "    )\n",
    "    \n",
    "    print(\"[+] Ground truth - Single view divergence: \\t\\t{}\".format(d_ground_single))\n",
    "\n",
    "    plot_distributions(\n",
    "        torch.Tensor(point_clouds[i]),\n",
    "        gen_clouds[i, 0, :3, :].permute(1,0),\n",
    "        [\"ground_truth\", \"single view\"], \n",
    "        i\n",
    "    )\n",
    "\n",
    "    # ---- ground truth cloud / multi view cloud\n",
    "    d_ground_multi = cloud_distance(\n",
    "        torch.Tensor(point_clouds[i]), \n",
    "        gen_clouds[i, 1, :3, :].permute(1,0)\n",
    "    )\n",
    "    print(\"[+] Ground truth - Multi view divergence: \\t\\t{}\".format(d_ground_multi))\n",
    "\n",
    "    plot_distributions(\n",
    "        torch.Tensor(point_clouds[i]),\n",
    "        gen_clouds[i, 1, :3, :].permute(1,0),\n",
    "        [\"ground_truth\", \"multi view\"], \n",
    "        i\n",
    "    )\n",
    "\n",
    "    # ---- single view cloud / multi view cloud\n",
    "    d_single_multi = cloud_distance(\n",
    "        gen_clouds[i, 0, :3, :].permute(1,0), \n",
    "        gen_clouds[i, 1, :3, :].permute(1,0)\n",
    "    )\n",
    "    print(\"[+] Single view - Multi view divergence: \\t\\t{}\".format(d_single_multi))\n",
    "\n",
    "    plot_distributions(\n",
    "        gen_clouds[i, 0, :3, :].permute(1,0), \n",
    "        gen_clouds[i, 1, :3, :].permute(1,0), \n",
    "        [\"single view\", \"multi view\"], \n",
    "        i\n",
    "    )\n",
    "    \n",
    "    scores[i, :] = torch.Tensor([d_ground_single, d_ground_multi, d_single_multi])\n",
    "        \n",
    "exec_time2 = np.mean(exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5ccf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endidx = gen_clouds.shape[0] if limit == -1 else limit+1\n",
    "\n",
    "ground_PIS = batched_PIS(clf, point_clouds[:endidx])\n",
    "single_PIS = batched_PIS(clf, gen_clouds[:, 0, :3, :].permute(0, 2, 1).cpu().numpy())\n",
    "multi_PIS = batched_PIS(clf, gen_clouds[:, 1, :3, :].permute(0, 2, 1).cpu().numpy())\n",
    "\n",
    "print(f\"[+] Ground truth clouds PIS: \\t\\t\\t{ground_PIS}\")\n",
    "print(f\"[+] Single-view generated clouds PIS: \\t\\t{single_PIS}\")\n",
    "print(f\"[+] Multi-view generated clouds PIS: \\t\\t{multi_PIS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c720c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_single_PFID = batched_PFID(clf, \n",
    "    point_clouds[:endidx],\n",
    "    gen_clouds[:, 0, :3, :].permute(0, 2, 1).cpu().numpy()                  \n",
    ")\n",
    "ground_multi_PFID = batched_PFID(clf, \n",
    "    point_clouds[:endidx],\n",
    "    gen_clouds[:, 1, :3, :].permute(0, 2, 1).cpu().numpy()\n",
    ")\n",
    "\n",
    "print(f\"[+] Ground truth - single view P-FID: \\t\\t{ground_single_PFID}\")\n",
    "print(f\"[+] Ground truth - multi view P-FID: \\t\\t{ground_multi_PFID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b997c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[-] Patch Concatenation - Avg. inference time: {exec_time}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b32aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
